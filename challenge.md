# Emotion Detection Challenge ðŸš€


Welcome, Your goal is to get this facial emotion recognition project running.


## ðŸ“‹ Instructions: Setup and Execution

Follow these steps carefully to set up your environment and run the code.

### Step 1: Clone the Project from GitHub

First, you need to download the project files from GitHub to your computer. This process is called "cloning." You have two easy options to do this.

#### Option A: Using the Command Line (Terminal)

1.  Open your terminal (on macOS/Linux) or Command Prompt/Git Bash (on Windows).
2.  Navigate to the directory where you want to store the project (e.g., `cd Documents/Projects`).
3.  Run the following command:
    ```bash
    git clone [https://github.com/7ser23/emotionUPB_2-2025.git](https://github.com/7ser23/emotionUPB_2-2025.git)
    ```
4.  This will create a new folder named `emotionUPB_2-2025` containing all the project files.

#### Option B: Using PyCharm

1.  Open PyCharm and, on the Welcome screen, click **Get from VCS** (Version Control System). 
2.  If PyCharm is already open, go to **File** -> **New** -> **Project from Version Control**.
3.  In the URL field, paste the repository link:
    ```
    [https://github.com/7ser23/emotionUPB_2-2025.git](https://github.com/7ser23/emotionUPB_2-2025.git)
    ```
4.  Choose a local directory where you want to save the project.
5.  Click **Clone**. PyCharm will download the project and set it up for you.

### 2. Project Structure

First, make sure your project files are organized correctly. The script expects the model and other files to be in specific locations.
```bash
emotionUPB/
â”œâ”€â”€ approach/
â”‚   â””â”€â”€ ResEmoteNet.py      # The Python file defining the model architecture
â”œâ”€â”€ train/
â”‚   â””â”€â”€ fer2013_model.pth   # The pre-trained model weights
â”œâ”€â”€ images/
â”‚   â””â”€â”€ test_image.jpg      # An image you want to test
â”œâ”€â”€ main.py                 # The main script you will run
â”œâ”€â”€ requirements.txt        # The list of Python packages needed
â””â”€â”€ README.md
```
**Note:** Sergio will provide you with the `approach/ResEmoteNet.py` and `train/fer2013_model.pth` files.

### 3. Create a Virtual Environment

It's best practice to use a virtual environment to keep project dependencies isolated.

```bash
# Create a virtual environment named 'venv'
python -m venv venv

# Activate the environment
# On Windows:
.\venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate
```
### 4. Install Dependencies

Install all the required Python libraries using the requirements.txt file.
```bash
pip install -r requirements.txt
```

### 5. Run the Code
Now you can run the emotion detector on an image. The --image argument tells the script which image file to use.
### 6. Provide an analysis of the code and how it works